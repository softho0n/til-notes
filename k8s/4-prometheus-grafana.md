# helm으로 k8s에 모니터링 시스템 구축하기

- helm은 k8s 패키지 매니징 툴로 pip와 npm과 비슷한 역할을 한다.
- helm을 이용해서 k8s 클러스터 모니터링 시스템인 prometheus와 grafana를 설치하는 과정을 기술했다.
- 먼저 설치 순서는 아래와 같다.
    - helm3
    - prometheus & grafana
    - DCGM exporter
        - 자세한 정보는 해당 [링크](https://docs.nvidia.com/datacenter/cloud-native/gpu-telemetry/dcgm-exporter.html#introduction)를 참조하자.

## Prometheus & Grafana

- Helm repository에 chart 추가 및 업데이트
    - Helm을 통해 Prometheus와 Grafana 차트를 추가하고 업데이트 해준다.
        
        ```bash
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo update
        ```
        
- Prometheus & Grafana configuration 파일 수정하기
    - 현재 구축된 k8s 클러스터의 storage class 라던지, 서비스의 포트라던지 따로 설정해서 사용할 때,
    - 아래 사항을 참고하여 커스텀하게 변경하여 사용하자.
    - 먼저 default 버전의 configuration 파일을 추출하자.
        
        ```bash
        helm inspect values prometheus-community/kube-prometheus-stack > ./kube-prometheus-stack.values
        ```
        
    - storage class를 따로 설정했다면 default storage class를 수정하자.
        
        ```bash
        vim ./kube-prometheus-stack.values
        
        storageSpec: 
              volumeClaimTemplate:
                spec:
                  storageClassName: nfs # Editor에서 storageClass 검색 후 전부 nfs 변경
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 50Gi # storage field 아래에 selector는 삭제해줘야 함.
        ```
        
    - Prometheus service 타입을 기존의 ClusterIP에서 NodePort로 변경하자.
        
        ```bash
        vim ./kube-prometheus-stack.values
        
        From: # 변경 전
        # Port to expose on each node
        # Only used if service.type is 'NodePort'
        #
         nodePort: 30090
        
        # Loadbalancer IP
        # Only use if service.type is "loadbalancer"
         loadBalancerIP: ""
         loadBalancerSourceRanges: []
        # Service type
        #
         type: ClusterIP
        
        To: # 변경 후
        # Port to expose on each node
        # Only used if service.type is 'NodePort'
        #
         nodePort: 30090
        
        # Loadbalancer IP
        # Only use if service.type is "loadbalancer"
         loadBalancerIP: ""
         loadBalancerSourceRanges: []
        # Service type
        #
         type: NodePort
        ```
        
    - `serviceMonitorSelectorNilUsesHelmValues` 값 수정 (기존: true: → 변경: false)
        
        ```yaml
        vim ./kube-prometheus-stack.values
        
        serviceMonitorSelectorNilUsesHelmValues: false
        ```
        
    - GPU device의 메트릭 수집을 위한 configMap 내용을 추가해주자.
        
        ```bash
        vim ./kube-prometheus-stack.values
        
        ## AdditionalScrapeConfigs allows specifying additional Prometheus scrape configurations. Scrape configurations
        ## are appended to the configurations generated by the Prometheus Operator. Job configurations must have the form
        ## as specified in the official Prometheus documentation:
        ## https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are
        ## appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility
        ## to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible
        ## scrape configs are going to break Prometheus after the upgrade.
        ##
        ## The scrape configuration example below will find master nodes, provided they have the name .*mst.*, relabel the
        ## port to 2379 and allow etcd scraping provided it is running on all Kubernetes master nodes
        ##
        additionalScrapeConfigs:
        - job_name: gpu-metrics
          scrape_interval: 1s
          metrics_path: /metrics
          scheme: http
          kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names:
              - gpu-operator
          relabel_configs:
          - source_labels: [__meta_kubernetes_pod_node_name]
            action: replace
            target_label: kubernetes_node
        ```
        
- Prometheus & Grafana 설치
    - `prometheus` namespace에 Prometheus와 Grafana가 정상적으로 설치될 것이다.
        
        ```bash
        helm upgrade --install kube-stack-prometheus prometheus-community/kube-prometheus-stack -n prometheus --create-namespace --values ./kube-prometheus-stack.values
        ```
        

## DCGM exporter

- GPU 디바이스의 상태 및 메트릭을 모니터링 하고싶다면 필수적으로 설치해야할 패키지이다.
- 먼저 Helm 차트를 통해 DCGM exporter를 repository에 추가시켜주자.
    
    ```bash
    helm repo add gpu-helm-charts https://nvidia.github.io/dcgm-exporter/helm-charts
    helm repo update
    ```
    
- DCGM exporter 설치를 진행하자.
    - `default` 네임스페이스에 gpu 메트릭 수집을 수행하는 pod가 생성될 것임.
    
    ```bash
    helm install --generate-name gpu-helm-charts/dcgm-exporter --set arguments=null
    ```
    
- 만약 해당 Pods 들이 Error를 발생시킨다면 아래 내용을 참고하여 시도해보자.
    - 에러가 발생한 Pod에 대해서 직접 yaml 파일을 직접 수정하여 적용하면 된다.
        
        ```bash
        # 먼저 해당 Pods의 정확한 이름을 파악한다.
        kubectl get daemonset.apps
        ```
        
    - 에러가 발생한 Pod의 정확한 이름을 알게되었다면 아래와 같이 수정해서 적용해보자.
        
        ```yaml
        kubectl edit daemonset.apps/dcgm-exporter
        
        spec:
              containers:
              - args:
                - -f
                - /etc/dcgm-exporter/dcp-metrics-included.csv
                env:
                - name: DCGM_EXPORTER_KUBERNETES
                  value: "true"
                - name: DCGM_EXPORTER_LISTEN
                  value: :9400
                - name: DCGM_EXPORTER_INTERVAL # 추가
                  value: "5000" # 추가
        
        ---
        initialDelaySeconds: 60 # 기존에는 아마 5로 되어있을 것임
        ```